---
title: "MENA Situation Diagnostic Tool."
author: "Data and Information Management and Analysis Unit (DIMA), UNHCR MENA Bureau - **Not for distribution**"
date: " `r format(Sys.Date(),  '%d %B %Y')`"
always_allow_html: yes
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
    includes:
        in_header: css/header.html
---

<link rel="stylesheet" href="css/unhcr-bootstrap.css">
<link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/unhcr-header.css">

```{r setup, include=FALSE, message = FALSE}

knitr::opts_chunk$set(echo = TRUE)


mainDir <- getwd()
mainDirroot <- substring(mainDir, 0 , nchar(mainDir) - 5)


library(knitr)
library(FactoMineR) ## Multiple correspondance analysis and classification
library(factoextra)
library(ggplot2)
library(reshape2)
library(plyr)
library(dplyr)
library(stringr)
library(corrplot)
library(psych)
library(bbplot)
library(scales)
library(ggiraph)
library(ggrepel)
library(Compind)
library(bbplot)


library(pander)
panderOptions('knitr.auto.asis', FALSE)

library(huxtable)

#install.packages("ggcorrplot")
library(ggcorrplot)

library(classInt)
library(viridis)

library(rgdal)
library(cartography)
library(SpatialPosition)
library(RColorBrewer)

library(kableExtra)
library(formattable)

library(DT)
library(gridExtra)

library(igraph)
library(qgraph)

#Left align text
left_align <- function(plot_name, pieces){
  grob <- ggplot2::ggplotGrob(plot_name)
  n <- length(pieces)
  grob$layout$l[grob$layout$name %in% pieces] <- 2
  return(grob)
}

```


UNHCR has developed a Diagnostic Tool to provide an evidence-based evaluation of the protection environment at the country level, in order to assist UNHCR representatives and their teams in determining key priority actions needed. There are three main objectives of the Protection Diagnostic Tool:

  1. Provide a structured snapshot of the current protection situation in an operation with regards to implementing key corporate priorities referenced in the Global Strategic priorities, directions, and policies.
  
  2.	Build a composite measurement of the operation situation.
  
  4.	Help identify key actions or strategies to be developed and applied as part of the planning exercise, and to inform the operation about good practices and required support both in terms of programmatic delivery as well as advocacy. 


Primary data was collected through an online questionnaire in [kobotoolbox](http://kobo.unhcr.org) consisting of **more than 180 questions**, each of tehm apparented to a "traffic light" type of question. Such amount of information is not directly digestable. In order to address this challenges, 10 composite indicators were built out of this questionnaire. This technical report documents the process used to develop those composite indicators.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Provide below the name of the form in xsl form - format should be xls not xlsx

scores.full <-  read.csv(paste0(mainDirroot,"/data/scorefull.csv"), sep = ",", encoding = "UTF-8", na.strings = "")
data <-  read.csv(paste0(mainDirroot,"/data/datafull.csv"), sep = ",", encoding = "UTF-8", na.strings = "")
questions <-  read.csv(paste0(mainDirroot,"/data/questions.csv"), sep = ",", encoding = "UTF-8", na.strings = "")


scores.full.wide <- dcast(scores.full, operation  ~ name, value.var = "score", sum)
row.names(scores.full.wide) <- scores.full.wide$operation
scores.full.wide$operation <- NULL

## get a vector with subregion for representation
subregion <- as.data.frame(data[order(data$intro.Operation), c("intro.SubRegion")])
names(subregion)[1] <- "subregion"

menamap <- readOGR(paste0(mainDirroot,"/data/menashape2.geojson"), verbose = FALSE)


```


Several steps are involved in creating composite indicators: Investigating the structure of simple indicators by means of correaltion analysis and multivariate statistics, bringing the indicators to the same unit bynormalization and finally selecting an appropriate weighting  and  aggregation model. For this project, we do not have missing data as the questionnaire was based on expert opinion. Due to the structure of the question a min-max approach has been used for the normalisation. For weighting, the main issue to adress is **compensability**, namely: to what extent can we accept that the high score of an indicator go to compensate the low score of another indicator? Equal weight and arithmetic addition are often coming the risk of misrepresenting the reality. This problem of compensability is intertwined with the issue of attribution of weights for each sub-indicator in order to calculate the final aggregation. 

In the following analysis workflow, indicators were initially mapped to the proposed composite. Then an analysis of correlation has been used to fiter the indicators that were the most likely to measure the proposed construct. Consistency was then check though a specific test and the usage of principal componnent analysis. Finally, Various options were calculated for each indicators. 

The analysis framework is organised around two main series of conceptual framework: themes & approaches. The 10 composite indicators displays the effects of all individual indicators. For this reason, a reflective (rather than formative) model has been found appropriate.


**6 Themes**:

  * Support to persons of concerns: includes SGBV, Child Protection, Health, Education, Livelihoods support, Cash Interventions, Social Protection integration.
  
  * Legal
  
  * Community: Community Based Protection &Communication with Communities 
  
  * Inclusion :  Development Planning, Contingency Planning and Preparedness
  
  * Advocacy 
  
  * Evidence:  Data Protection, Data & Information Management
  
**4 Approaches**:  

  * Environment: informing on the expected situation according to regulations.

  * Situation: informing on the actual situation despite legal regulations.  
  
  * Access: informing on UNHCR’s ability to engage in the country of operation.

  * Compliance: informing on the operation compliance regarding Global Initiative & Policies.




# **Support**

This topic groups all indicators related to the capacity to offer direct support and basic services to refugees and persons of concerns. 

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

# Support
# Legal
# Community
# Inclusion
# Evidence
# Advocacy



this.topic <- "Support"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$theme == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name", "variation.coeff1",
                                 "variation.coeff" )]
questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL
row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep
indic.this <- as.character(questions[ questions$theme == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                      c("name" )])



scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}

#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)


corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))


## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}

```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator

Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"



# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"



## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method


#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")

## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )

scores.this.pos.reduced22$Factor <- NULL

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm



## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic



scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))



```



# **Legal**

This topic groups all indicators related to the legal dimensions prevailing in each country. 

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

# Support
# Legal
# Community
# Inclusion
# Evidence
# Advocacy



this.topic <- "Legal"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$theme == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name", "variation.coeff1",
                                 "variation.coeff" )]
questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL
row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$theme == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))

## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```



## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}


#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)


corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

## ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))
## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}


```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator

Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.



```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"



scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")

## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )

scores.this.pos.reduced22$Factor <- NULL
## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm



## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic



scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))



```


# **Community**

This topic groups all indicators related to Community based protection and Communinication with communities. 

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

# Support
# Legal
# Community
# Inclusion
# Evidence
# Advocacy



this.topic <- "Community"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$theme == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name", "variation.coeff1",
                                 "variation.coeff" )]
questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL


row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$theme == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}

#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)


corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))

## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}


```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator



Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"



scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")

## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )


scores.this.pos.reduced22$Factor <- NULL
## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm



## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic


scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))



```


# **Inclusion**

This topic groups all indicators related to the opportunities for refugees to integrate in the country of asylum. 

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

# Support
# Legal
# Community
# Inclusion
# Evidence
# Advocacy



this.topic <- "Inclusion"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$theme == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name", "variation.coeff1",
                                 "variation.coeff" )]
questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL


row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$theme == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}

#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)



corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))

## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}


```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA  allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")

#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator


Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"



scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")

## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )

scores.this.pos.reduced22$Factor <- NULL
## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm



## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic


scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))



```





# **Advocacy**

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

# Support
# Legal
# Community
# Inclusion
# Evidence
# Advocacy



this.topic <- "Advocacy"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$theme == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name", "variation.coeff1",
                                 "variation.coeff" )]
questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL


row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$theme == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}

#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)



corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))
## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}



```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA  allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator


Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"


scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")

## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )

scores.this.pos.reduced22$Factor <- NULL
## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm




## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic


scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))



```

# **Evidence**

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

# Support
# Legal
# Community
# Inclusion
# Evidence
# Advocacy



this.topic <- "Evidence"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$theme == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name", "variation.coeff1",
                                 "variation.coeff" )]
questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL


row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$theme == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}

#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)



corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))
## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}


```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA  allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator

Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.



```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"


scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")

## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )

scores.this.pos.reduced22$Factor <- NULL
## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm




## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic


scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))



```



# **Compliance**

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

this.topic <- "Compliance"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$concept == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name","variation.coeff1",
                                 "variation.coeff" )]

questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL

row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$concept == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}

#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)


corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))
## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}


```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA  allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator


Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"


scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")

## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )

scores.this.pos.reduced22$Factor <- NULL
## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm



## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic


scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))





```




# **Access**

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

this.topic <- "Access"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$concept == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name","variation.coeff1",
                                 "variation.coeff" )]

questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL


row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$concept == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}
#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)



corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))
## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}


```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA  allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator


Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"


scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")


## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )

scores.this.pos.reduced22$Factor <- NULL


## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm



## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic


scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))



```


# **Situation** 

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

this.topic <- "Situation"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$concept == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name","variation.coeff1",
                                 "variation.coeff" )]

questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL


row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$concept == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}
#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation
       negCol = "#FF9933", ## Color negative correlation
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)



corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))
## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}


```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator

Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"


scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")


## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )


scores.this.pos.reduced22$Factor <- NULL


## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm


## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic


scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))






```

#  **Environment**

## List of considered Indicators

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

this.topic <- "Environment"
## Remove where scores max is NA or 0

questions.this <- questions[ questions$concept == this.topic &
                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                 "label","name","variation.coeff1",
                                 "variation.coeff" )]

questions.this <- questions.this[order( -questions.this$variation.coeff1),]
questions.this$variation.coeff1 <- NULL


row.names(questions.this) <- NULL

cat(paste0("An initial mapping of indicators to this construct has been performed. The following ", nrow(questions.this), " indicators have been considered. \n"))

kable(questions.this, caption = "Variation Coeff. for considered Indicators") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 9)

## Get lits of indic to keep

indic.this <- as.character(questions[ questions$concept == this.topic &
                                        (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name" )])

scores.this <- scores.full.wide[ , indic.this]

## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this))
## Handle negative scores
for (i in 1:ncol(scores.this)) {
  for (j in 1:nrow(scores.this)) {
  scores.this[j ,i] <- ifelse( min(scores.this[ ,i]) < 0 ,
                              (scores.this[j ,i] + abs(min(scores.this[ ,i]))) ,
                              scores.this[j ,i]) 
     }
}

indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )


## Normalisation with Min Max -- with Compind packages
scores.this.norm.obj <- normalise_ci(scores.this,
                                  c(1:ncol(scores.this)),
                                  polarity =  polarity,
                                  method = 2)

scores.this.norm <- scores.this.norm.obj$ci_norm
```




## Correlation & Consistency


An important step, before proceeding with weighting & aggregation rules, and as described in the [OECD Handbook on Constructing Composite Indicators](http://www.oecd.org/sdd/42495745.pdf#page=34) is to look at correlations and consistency between indicators. 

### Analysis of correlation 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width = 10, fig.height = 10, size="small"}

#corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")
corr.matrix <- cor(scores.this.norm, method = "pearson",  use = "pairwise.complete.obs")

## replace with Label inside the matrix
corr.matrix1 <- corr.matrix
rownames(corr.matrix1) <- as.character(questions[questions$name %in% rownames(corr.matrix), c("label")])
colnames(corr.matrix1) <- as.character(questions[questions$name %in% colnames(corr.matrix), c("label")])

plot1 <- ggcorrplot(corr.matrix1 ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Identified Correlation between indicators",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 7),
         strip.text.x = element_text(size = 7),
         legend.position = "top",
         legend.box = "horizontal",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)


## Trying to get a network viz of indicator correlation
## http://sachaepskamp.com/files/Cookbook.html#customizing-graphs
indic.this.label <- as.character(questions[ questions$theme == this.topic &
                                              (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) ,
                                            c("label" )])

qgraph(cor(scores.this.norm),
     # shape = "circle",
     # posCol = "darkgreen",
     # negCol = "darkred",
     # threshold = "bonferroni", #The threshold argument can be used to remove edges that are not significant.
     # sampleSize = nrow(scores.this.norm),
     # graph = "glasso",
       esize = 35, ## Size of node
       vsize = 6,
       vTrans = 600,
       posCol = "#003399", ## Color positive correlation Dark powder blue
       negCol = "#FF9933", ## Color negative correlation Deep Saffron
       alpha = 0.05,
       cut = 0.4, ## cut off value for correlation
       maximum = 1, ## cut off value for correlation
       palette = 'pastel', # adjusting colors
       borders = TRUE,
       details = FALSE,
       layout = "spring",
       nodeNames = indic.this.label,
       legend.cex = 0.4,
       title = "Correlations Network",
       line = -2,
       cex.main = 2)

corr.matrix0 <- corr.matrix
diag(corr.matrix0) <- 0

##set up threhsold
threshold <- 0.5

# ok <- apply(abs(corr.matrix0) >= threshold, 1, any)
ok <- apply( corr.matrix0 >= threshold, 1, any)
# ok <- sort(unique( c(which(abs(corr.matrix0) >= threshold, arr = TRUE))))
# ok <- sort(unique( c(which(corr.matrix0 >= threshold, arr = TRUE))))
# ok <- (which(sapply(df2,function(x) any(x > threshold, na.rm = TRUE))))

cat(paste0("Indicators with low level of correlation are excluded from the rest of the analysis. \n After this step, we keep ", length(ok), " out of the ", nrow(questions.this)," initial indicators. \n"))
## display new chart if needed
if (length(ok) < nrow(questions.this)) {
corr.matrixnew <-  corr.matrix[ok, ok]
scores.this.pos.reduced <- scores.this.norm[ , ok]

plot1 <- ggcorrplot(corr.matrixnew ,
                    method = "circle",
                    hc.order = TRUE,
                    type = "upper") +
  labs(title = paste0( "Selected Indicators for ",this.topic ),
       subtitle = "Correlation between indicators > 0.5",
       caption = "Correlation level = dot size, Positive Correlation  = Red - Negative = Blue",
       x = NULL, y = NULL) +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         legend.position = "right",
         legend.box = "vertical",
         legend.text = element_text(size = 9),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_line(color = "#cbcbcb"))
ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1)

} else {
  scores.this.pos.reduced <- scores.this.norm[ , ok]
}


```

### Consistency: Cronbach Alpha


Cronbach Alpha is an estimate  of  internal  consistency 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

Cronbach.this <- psych::alpha(scores.this.pos.reduced, check.keys = TRUE)

cat(paste0("The Cronbach Alpha measure of consistency for this combination of indicators is  ", round(Cronbach.this$total$std.alpha, 2) ) )
```

### Consistency: Principal Components Analysis (PCA)

PCA  allows to analyze the underlying structure of the data, i.e how different indicators can be grouped together (each group of indicators is called a factor). The goal of principal components analysis (PCA) is to reveal how different variables change inrelation to each other and how they are associated.

Note that with small sample like here, such analysis shoudl be taken with caution since results do not have known statistical properties. 

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message= TRUE, comment = "", fig.width= 10, size="small"}

### Definition of dimensions ####
res.pca <- prcomp(scores.this.pos.reduced, scale = TRUE)
# Visualize eigenvalues (scree plot). 

cat("The screeplot show the percentage of variances explained by each principal component.")
fviz_eig(res.pca, main = "Screeplot")


#### extracting value from pca...
var <- get_pca_var(res.pca)
var.contrib <- as.data.frame(var$contrib)
var.contrib$name <- row.names(var.contrib)
var.contrib <- merge(x = var.contrib, y = questions[ , c("name", "label")], by = "name")


var.contrib1 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib1 <- var.contrib1[1:10,]

plot1 <- ggplot(var.contrib1, aes(x = reorder(var.contrib1$label, var.contrib1$Dim.1 ), y = var.contrib1$Dim.1)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 1",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))

# Contributions of variables to PC2
#fviz_contrib(res.pca,
#             choice = "var",
#             axes = 2,
#             top = 10)
var.contrib2 <- var.contrib[with(var.contrib,order(-Dim.1)),]
var.contrib2 <- var.contrib2[1:10,]

plot1 <- ggplot(var.contrib2, aes(x = reorder(var.contrib2$label, var.contrib2$Dim.2 ), y = var.contrib2$Dim.2)) +
  geom_bar(fill = "#2a87c8",colour = "#2a87c8", stat = "identity", width = .8) +
  guides(fill = FALSE)  +
  coord_flip() +
  xlab("") +
  labs(title = "Axe 2",
       subtitle = "Top 10 Indicators Respective Contribution",
       caption = "Diagnostic MENA") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"),
         panel.grid.major.y = element_blank())

print(ggpubr::ggarrange(left_align(plot1, c("subtitle", "title")), ncol = 1, nrow = 1))


# Graph of individuals #####
## clusters
ind.p <- fviz_pca_ind(res.pca,
                      col.ind = subregion$subregion, # color by groups
                      pointsize = "cos2",
                      pointshape = 21, #fill = "#E7B800",
                      palette = c("#00AFBB", "#E7B800", "#FC4E07"),
                      #  addEllipses = TRUE, # Concentration ellipses
                      legend.title = "Groups"
)

ggpubr::ggpar(ind.p,
              title = paste0("Profile for ", this.topic ),
              subtitle = "Principal Component Analysis",
              caption = "Diagnostic Tool",
              xlab = "Axe 1", ylab = "Axe 2",
              legend.title = "Subregion",
              legend.position = "right",
              ggtheme = theme_minimal()
)


```





## Building composite indicator


Various algorithms are then tested to build the composite indicators. Details on each algoritm are available in the annex.


```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

## Asumme all polarity are positive
indicdescr2 <- as.data.frame(names(scores.this.pos.reduced))
indicdescr2$polarity <- "POS"
indicdescr2$dir <- 1
polarity2 <- as.character(indicdescr2$polarity )
direction2 <- as.numeric(indicdescr2$dir )



#  Benefit of the Doubt approach #######
CI_BoD_estimated = ci_bod(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_bod_est <- as.data.frame( CI_BoD_estimated$ci_bod_est)
names(ci_bod_est) <- "Benef_Doubt"

## Directional Benefit of the Doubt (D-BoD) model
# Directional Benefit of the Doubt (D-BoD) model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.

## Endogenous weight - no zero weight --

CI_Direct_BoD_estimated <-  ci_bod_dir(scores.this.pos.reduced,
                                      indic_col = (1:ncol(scores.this.pos.reduced)),
                                       dir = direction2)

ci_bod_dir_est <- data.frame(CI_Direct_BoD_estimated$ci_bod_dir_est)
names(ci_bod_dir_est) <- "Benef_Doubt_Dir"



## Robust Benefit of the Doubt approach (RBoD) ########
CI_RBoD_estimated <-  ci_rbod(scores.this.pos.reduced,
                              indic_col = (1:ncol(scores.this.pos.reduced)),
                              M = 20,  #The number of elements in each sample.
                              B = 200) #The number of bootstap replicates.


ci_rbod_est <- data.frame(CI_RBoD_estimated$ci_rbod_est)
names(ci_rbod_est) <- "Benef_Doubt_Rob"


#BoD index with the constraints on weights 
#(so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto
#(also adopted by the Italian National Institute of Statistics) 
CI__BoD_MPI_estimated = ci_bod_constr_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                       up_w = 1,
                       low_w = 0.1,
                       penalty = "POS")

ci_bod_constr_est_mpi <- data.frame(CI__BoD_MPI_estimated$ci_bod_constr_est_mpi)
names(ci_bod_constr_est_mpi) <- "Benef_Doubt_Cons"




## Geometric aggregation ########
# lets to bypass the full compensability hypothesis using geometric mean.

CI_Geom_estimated = ci_geom_gen(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                                  meth = "EQUAL",   
                       ## "EQUAL" = Equal weighting set, "BOD" = Benefit-of-the-Doubt weighting set.
                                   up_w = 1,
                                   low_w = 0.1,
                                  bench = 1) 
                       # Row number of the benchmark unit used to normalize the data.frame x.

ci_mean_geom_est <- data.frame( CI_Geom_estimated$ci_mean_geom_est)
names(ci_mean_geom_est) <- "Mean_Geom"

## Mazziotta-Pareto Index (MPI) #####
# a non-linear composite index method which transforms a set of individual indicators in
# standardized variables and summarizes them using an arithmetic
# mean adjusted by a ”penalty” coefficient related to the variability
# of each unit (method of the coefficient of variation penalty).

CI_MPI_estimated <- ci_mpi(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)),
                          penalty = "POS")  # Penalty direction; ”POS” (default) in case of increasing
                                          #  or “positive” composite index (e.g., well-being index),
                                          #  ”NEG” in case of decreasing or “negative” composite
                                          #  index (e.g., poverty index).

ci_mpi_est <- data.frame( CI_MPI_estimated$ci_mpi_est)
names(ci_mpi_est) <- "Mazziotta_Pareto"

## Mean-Min Function (MMF)  #####
# an intermediate case between
# arithmetic mean , according to which no unbalance is penalized, and
# min function, according to which the penalization is maximum.

CI_mean_min_estimated <- ci_mean_min(scores.this.pos.reduced,
                                    indic_col = (1:ncol(scores.this.pos.reduced)),
                                    alpha = 0.5,  #intensity of penalization of unbalance  (α)
                                    beta = 1) # intensity of complementarity (β) among indicators

ci_mean_min_est <- data.frame( CI_mean_min_estimated$ci_mean_min_est)
names(ci_mean_min_est) <- "Mean_Min"


## Wroclaw taxonomy method ####
# (also known as the dendric method), originally developed at the University of Wroclaw, is
# based on the distance from a theoretical unit characterized by the
# best performance for all indicators considered.

CI_wroclaw_estimated <-  ci_wroclaw(scores.this.pos.reduced,
                       indic_col = (1:ncol(scores.this.pos.reduced)))

ci_wroclaw_est <- data.frame( CI_wroclaw_estimated$ci_wroclaw_est)
names(ci_wroclaw_est) <- "Wroclaw"




# Factor analysis #############
# groups together collinear simple indicators to estimate a composite indicator
# that captures as much as possible of the information common to individual indicators.

##  Doing PCA with ci_factor.R
# If method = "ONE" (default) the composite indicator estimated values are equal to first component scores;
# if method = "ALL" the composite indicator estimated values are equal to component score multiplied by its proportion variance;
# if method = "CH" it can be choose the number of the component to take into account.

dimfactor <- ifelse(ncol(scores.this.pos.reduced) > 2, 3, ncol(scores.this.pos.reduced))

CI_Factor_estimated <-  ci_factor(scores.this.pos.reduced,
                                   indic_col = (1:ncol(scores.this.pos.reduced)),
                                   method = "CH",  # if method = "CH" it can be choose the number of the component to take into account.
                                   dim = dimfactor)
ci_factor_est <- data.frame( CI_Factor_estimated$ci_factor_est)
names(ci_factor_est) <- "Factor"


scores.this.pos.reduced2 <- cbind( #row.names(scores.this),
                  ci_bod_est, # Benefit of the Doubt approach
                  ci_rbod_est, # Robust Benefit of the Doubt approach
                  ci_bod_dir_est, # Directional Robust Benefit of the Doubt approach
                  ci_bod_constr_est_mpi, # DRobust Benefit of the Doubt approach with constraint 
                  ci_factor_est, # Factor analysis  componnents
                  ci_mean_geom_est, # Geometric aggregation
                  ci_mean_min_est, # Mean-Min Function
                  ci_mpi_est, # Mazziotta-Pareto Index
                  ci_wroclaw_est) # Wroclaw taxonomy method

#names(scores.this.pos.reduced2)[1] <- "Operation"
#row.names(scores.this.pos.reduced2) <- NULL


#datatable(scores.this.pos.reduced2, filter = 'bottom', options = list(pageLength = 15)) %>%
#    formatStyle('row.names(scores.this.pos.reduced2)',color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
#                backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
#                fontWeight = styleInterval(58.0, c('italics', 'bold')))

#scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced2[, colSums(scores.this.pos.reduced2 != 0, na.rm = TRUE) > 0]
scores.this.pos.reduced22 <- scores.this.pos.reduced22[, colSums(scores.this.pos.reduced22 != 0, na.rm = TRUE)  == nrow(scores.this.pos.reduced22)]


kable(scores.this.pos.reduced22,
              caption = "Results according different kind of aggregation") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8)

cat("Indicators can be normalised again on a 0 to 1 scale in order to be compared. \n")

## keep that frame for later on for the viz
assign(  paste("scores.", this.topic, sep = ""), scores.this.pos.reduced22$Wroclaw )

scores.this.pos.reduced22$Factor <- NULL



## Asumme all polarity are positive
indicdescr <- as.data.frame(names(scores.this.pos.reduced22))
indicdescr$polarity <- "POS"
indicdescr$dir <- 1
polarity <- as.character(indicdescr$polarity )
direction <- as.numeric(indicdescr$dir )
## Normalisation with Min Max -- with Compind packages
scores.this.pos.reduced3 <- normalise_ci(scores.this.pos.reduced22,
                                     c(1:ncol(scores.this.pos.reduced22)),
                                     polarity =  polarity,
                                     method = 2)

scores.this.pos.reduced3 <- scores.this.pos.reduced3$ci_norm



## Invert Worclaw so that it looks consistent with others
scores.this.pos.reduced3$Wroclaw <- 1 - scores.this.pos.reduced3$Wroclaw

## Remove NaN
scores.this.pos.reduced3 <- scores.this.pos.reduced3[, colSums(scores.this.pos.reduced3 != 0, na.rm = TRUE) > 0]

scores.this.pos.reduced3.keep <- as.data.frame(scores.this.pos.reduced3[ , c("Wroclaw")])
names(scores.this.pos.reduced3.keep)[1] <- this.topic


scores.this.pos.reduced3.melt <- melt(as.matrix(scores.this.pos.reduced3))


#Make plot
line <- ggplot(scores.this.pos.reduced3.melt, aes(x = Var2, 
                                                  y = value, 
                                                  color = Var1, 
                                                  group = Var1)) +
  geom_line(size = 2) +
   scale_colour_manual(values = c("#8dd3c7","#A6CEE3", "#1F78B4", "#B2DF8A", "#33A02C", "#FB9A99", "#E31A1C", "#FDBF6F", "#FF7F00", "#CAB2D6", "#6A3D9A", "#fb8072", "#B15928", "#fdb462","#ccebc5" )) +
  geom_text_repel(
    data = scores.this.pos.reduced3.melt[ scores.this.pos.reduced3.melt$Var2 == "Wroclaw", ],
    aes(label = Var1),
    arrow = arrow(length = unit(0.03, "npc"), type = "closed", ends = "first"),
    direction =	"y",
    size = 6,
    nudge_x = 45 ) + 
  labs(title = paste0("Country Rank for Composite Indicator on ",  this.topic ),
       subtitle = "Based on various weighting approach") +
  bbc_style() +
  theme( plot.title = element_text(size = 13),
         plot.subtitle = element_text(size = 11),
         plot.caption = element_text(size = 7, hjust = 1),
         axis.text = element_text(size = 10),
         strip.text.x = element_text(size = 11),
         panel.grid.major.x = element_line(color = "#cbcbcb"), 
         panel.grid.major.y = element_blank(),
         legend.position = "none")
  
print(ggpubr::ggarrange(left_align(line, c("subtitle", "title")), ncol = 1, nrow = 1))



```


# Results Visualization

Wroclaw taxonomy method provides the most consistent results for indicator composition. It is not surprising as this method is based on the distance from a theoretical unit characterized by the best performance for all indicators considered, which reflects the underlying approach within the questionnaire.

## By indicator

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small",  results='asis'}

# example data:
all.score <- cbind(as.character(data$intro.Operation),
                   scores.Support,
                   scores.Legal,
                   scores.Community,
                   scores.Inclusion,
                   scores.Evidence,
                   scores.Advocacy,
                   scores.Compliance,
                   scores.Access,
                   scores.Situation,
                   scores.Environment)

## Create a consistent color palette
palette <- c( "#a6cee3",
              "#1f78b4",
              "#b2df8a",
              "#33a02c",
              "#fb9a99",
              "#e31a1c",
              "#fdbf6f",
              "#ff7f00",
              "#cab2d6",
              "#6a3d9a")

group <- c(    "Support",
               "Legal",
               "Community",
               "Inclusion",
               "Evidence",
               "Advocacy",
               "Situation",
               "Environment",
               "Compliance",
               "Access")
names(palette) <- group


#plot(menamap)

#names(all.score)
#data$intro.Operation

iso3 <- c("SYR", #SyrianArabRepublic
             "YEMN", #NorthYemen
             "YEMS", #SouthYemen
             "LBN", #Lebanon 
             "MRT", #Mauritania
             "TUN", #Tunisia 
             "DZA", #Algeria
             "MAR", #Morocco
             "LBY", #Libya
             "EGY", #Egypt
             "ISR", #Israel 
             "ARE", #UnitedArabEmirates
             "SAU", #SaudiArabia
             "JOR", #Jordan
             "IRQ") # Iraq  
             
all.score2 <- as.data.frame(cbind(all.score, iso3) )

for (i in 2:11) {
  # i <- 2
  all.score2[ ,i] <- round(as.numeric(as.character(all.score2[ ,i])),2)*100
}

all.score2$id <- all.score2$iso3
menamap2 <- menamap[ menamap$iso3 %in% iso3, ]
#plot(menamap2)
## Fortify
menamap2.fort <- fortify(menamap2, region = "iso3")

menamap2.map.fort <- merge( x = menamap2.fort, y = all.score2, by = "id", all.x = TRUE )
rm(menamap.fort)

## Extract centroid to display lable on map
cnames <- aggregate(cbind(long, lat) ~ iso3, data = menamap2.map.fort,
                    FUN = function(x)mean(range(x))) #Andrie's code
names(cnames)[2] <- "Longitude"
names(cnames)[3] <- "Latitude"
cnames <- merge( x = cnames, y = all.score2, by = "iso3", all.x = TRUE )


## Data to display
data1 <- data
row.names(data1) <- data1$intro.Operation


for (i in 1:length(group)) {
 # i <- 1
  group.this <- as.character(group[i])
 # cnames[ , i + 4 ] <- round(cnames[ , i + 4 ],2)*100

ggplot() +
  geom_polygon(data = menamap2.map.fort, aes(x = long, y = lat,  group = group,
                                             fill = menamap2.map.fort[ , i + 8]),
               colour = "white", alpha = 0.6 ) +

 #ggplot() +
  geom_text(data = cnames, aes(x = Longitude, y = Latitude, label = cnames[ , i + 4 ]) , size = 3)
  
  print(
    ggplot() +
      geom_polygon(data = menamap2.map.fort,
           aes(x = long, y = lat,  group = group, 
               fill = menamap2.map.fort[ , i + 8]), colour = "white", alpha = 0.6 ) +
      scale_fill_viridis_c() +
      geom_text(data = cnames, aes(x = Longitude, y = Latitude, 
                                 label = cnames[ , i + 4 ]), size = 3) +
      coord_equal() +
      labs( title = paste0("Composite Indicator for ",  group.this ), 
            subtitle = "Wroclaw taxonomy method - Indicator from 0 to 100", 
            caption = "UNHCR diagnostic Tool",
            x = NULL, y = NULL) +
      
      bbc_style() +
      theme(legend.position = "bottom",
            axis.line = element_blank(),
            axis.text.x = element_blank(),
            axis.text.y = element_blank(),
            axis.ticks = element_blank(),
            axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.text.align = 0, 
            legend.background = element_blank(),
            legend.text = element_text(size = 7, hjust = 0, color = "#4e4d47"),  
            legend.title = element_blank(), 
            plot.title = element_text(size = 13),
            plot.subtitle = element_text(size = 11),
            plot.caption = element_text(size = 7),
            panel.grid.major.y = element_blank() ) 
    )
  
  ### get a table with all indic response
  
  questions.thislabel <- as.character(questions[ questions$theme == this.topic  | questions$concept == this.topic &
                                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c(#"type",
                                                 "label")])
  
  
  questions.thisfullname <- as.character(questions[ questions$theme == this.topic  | questions$concept == this.topic &
                                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("fullname")])
  
  
  questions.thisname <- as.character(questions[ questions$theme == this.topic  | questions$concept == this.topic &
                                               (!(is.na(questions$maxscore)) & questions$maxscore != 0 ) , c("name")])
  
  ## Now rename and split df by middle-east  vs North Africa
  
  
  data2 <- data1[ , questions.thisfullname]
  names(data2) <- questions.thislabel
  data2 <- t(data2) 
    
  score.wide.this <- scores.full.wide[ , questions.thisname]
  names(score.wide.this) <- questions.thislabel
  score.wide.this <- t(score.wide.this)
  

  
 # pandoc.table(data2[ ,c( "SyrianArabRepublic", "Lebanon", "Egypt","Jordan","Iraq" )], caption = "Indicators for Syria Crisis")
 # pandoc.table(score.wide.this[ ,c( "SyrianArabRepublic", "Lebanon", "Egypt","Jordan","Iraq" )], caption = "Indicators for Syria Crisis")
  
 
  print(kable(score.wide.this[ ,c( "SyrianArabRepublic", "Lebanon", "Egypt","Jordan","Iraq" )],
              caption = "Indicators for Syria Crisis") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8) )
  
 # print(kable(data2[ ,c("Mauritania","Tunisia","Algeria","Morocco","Libya" )], caption = "Indicators for North Africa")%>%
 #          kable_styling(c("striped", "bordered")))
  print(kable(score.wide.this[ ,c("Mauritania","Tunisia","Algeria","Morocco","Libya" )],
              caption = "Indicators for North Africa") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8))
  
  
  print(kable(score.wide.this[ ,c( "NorthYemen","SouthYemen","UnitedArabEmirates","SaudiArabia", "Israel")],
              caption = "Indicators for Gulf & Israel") %>%
           kable_styling(bootstrap_options = c("striped", "bordered", "condensed", "responsive"), font_size = 8))
  
 # print(as_hux(data2[ ,c( "NorthYemen","SouthYemen","UnitedArabEmirates","SaudiArabia", "Israel")], caption = "Indicators for Gulf & Israel"))
 # print(as_hux(score.wide.this[ ,c( "NorthYemen","SouthYemen","UnitedArabEmirates","SaudiArabia", "Israel")], caption = "Indicators for Gulf & Israel"))
  
  
}




```

## By countries

```{r, echo=FALSE, warning=FALSE, cache=FALSE, tidy = TRUE, message=FALSE, comment = "", fig.width= 10, size="small"}

for (i in 1:nrow(all.score)) {
  # i <- 1
  operation <- as.character(all.score2[ i , 1])
  
## Scores for topic
df0 <- as.data.frame(t(all.score2[ i , 2:7]))
names(df0)[1] <- "value"
df0$group <- row.names(df0)
df1 <- df0 %>%
  filter(!is.na(group)) %>%
  mutate(group2 = gsub(" ", "\n", group),
         group = ifelse(toupper(group) == "A", "Temp@", group)) %>%
  add_row(group = "A", value = 0, .before = 1) %>%
  mutate(value_scale = value  ,
         value_sc_half = value / 2 ,
         aim = rep(50, nrow(.)))
df1_sub <- filter(df1, group != "A")

## Graph polar 1 
scoreplot1 <-  ggplot(df1, aes(x = group, fill = group)) +
  ## Data Bar
  geom_bar( aes(y = value_scale), 
            width = 0.85, stat = "identity",  colour = "white", fill = "white") +
  ylim(0, 100) + 
  ## Background bar
  geom_bar(data = df1_sub, aes(y = aim), 
           width = 0.85,  stat = "identity", colour = "grey68", fill = "white") +
  ## Data Bar
  geom_bar_interactive(data = df1_sub, aes(y = value_sc_half, fill = group2), 
                       width = 0.85, stat = "identity", colour = "white") +
  ## Turn into polar
  coord_polar(theta = "y", start = -1.57) + 
  
  ## Colors 
  scale_colour_manual(name = "group",values = palette) +
  
  ## labels
  geom_text(data = df1_sub, vjust = 2, hjust = 1, size = 3, angle = 45, aes(x = group2, y = 0, label = group2)) +
  xlab("") + 
  ylab("") +
  labs(title = paste0("Composite Indicator for ",  operation ),
       subtitle = "For topics") +
  
  ## Style
  theme_classic() +
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        plot.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "pt"))




## Scores for Approach
df02 <- as.data.frame(t(all.score2[ i , 8:11]))
names(df02)[1] <- "value"
df02$group <- row.names(df02)
df2 <- df02 %>%
  filter(!is.na(group)) %>%
  mutate(group2 = gsub(" ", "\n", group),
         group = ifelse(toupper(group) == "A", "Temp@", group)) %>%
  add_row(group = "A", value = 0, .before = 1) %>%
  mutate(value_scale = value ,
         value_sc_half = value / 2 ,
         aim = rep(50, nrow(.)))
df2_sub <- filter(df2, group != "A")


## Graph polar 2 
scoreplot2 <-  ggplot(df2, aes(x = group, fill = group)) +
  ## Data Bar
  geom_bar( aes(y = value_scale), 
            width = 0.85, stat = "identity",  colour = "white", fill = "white") +
  ylim(0, 100) + 
  ## Background bar
  geom_bar(data = df2_sub, aes(y = aim), 
           width = 0.85,  stat = "identity", colour = "grey68", fill = "white") +
  ## Data Bar
  geom_bar_interactive(data = df2_sub, aes(y = value_sc_half, fill = group2), 
                       width = 0.85, stat = "identity", colour = "white") +
  ## Turn into polar
  coord_polar(theta = "y", start = -1.57) +
  
  ## Colors 
  scale_colour_manual(name = "group",values = palette) +
  
  ## labels
  geom_text(data = df2_sub, vjust = 2, hjust = 1, size = 3, angle = 45, aes(x = group2, y = 0, label = group2)) +
  xlab("") + 
  ylab("") +
  # labs(title = paste0("Composite Indicator for ",  operation ),
  labs(title = "",
       subtitle = "For Approach") +
  
  ## Style
  theme_classic() +
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        plot.margin = margin(t = 0, r = 0, b = 0, l = 0, unit = "pt")) 
  
## now printing both in a grid

      grid.arrange(
      ggpubr::ggarrange(left_align(scoreplot1, c("subtitle", "title")), ncol = 1, nrow = 1) ,
      ggpubr::ggarrange(left_align(scoreplot2, c("subtitle", "title")), ncol = 1, nrow = 1) , 
      nrow = 1)
    
  
  
}
```



# Annex: Methodology

The methodology used here follows the steps described in the [OECD handbook for composite Indicators calculation](https://www.oecd.org/sdd/42495745.pdf) and inline the [European Joint Research Training on Composite Indicators](https://goo.gl/oULGgt). 





## Sub-Indicators calculation & Normalisation


The survey has two types of responses: ‘select_one’ and ‘select_multiple’. The negative questions receive a score of 1 when answered positively, such as answering “no”, and the score was lowered towards 0 with each negative response given.

The majority of the ‘select_one’ response choices is ordinal data with an imputed ordered response, where the max score of best possible choice is 1. However, the majority of the ‘select_multiple’ response choices are discrete choice data with nominal responses; each answer in the ‘select_multiple’ is weighted equally so that the total sum score of all choices is 1 for positive questions and 0 for questions with inverted meanings.


The weight of each country response modality to a question ranged from 0 to 1.  Different calculation were used depending on the type of questions.  For example, “select_one” questions might have 4 different options where the max of these scores represented the highest score possible, whereas “select_multiple” questions might have many dummy variables corresponded to the question and the sum of these scores represented the highest score possible.  Furthermore, negatively phrased questions needed to be weighted such that 0 was the lowest score, and 1 was the highest score.  Therefore, those questions which were negative started with a score of 1 by default. 


Each question was normalized, using a min-max method, so that 0 corresponds to the lowest possible score a respondent could get, and 1 corresponds to the highest possible score.  Therefore, the resulting score for the questions above, and all the questions in the survey, were divided by the total points possible. The conceptual areas were averaged so that the weighted adjusted scores are observed by percentage point of total, and ‘traffic light’ colors were designated as Red (0% - 30%), Yellow (30% - 60%), and Green (60% - 100%). 


## Cronbach’s alpha for each composite indicators

In order to investigate the degree of consistency among the questions selected for the conceptual areas, the Cronbach coefficient alpha, the most common estimate of internal consistency, was used to analyze the questions used. 



## Principal componnent Analysis

Using Principal componnent analysis, involves a few steps:

 *  Check the correlation structure of the data: porrly correlated indicators are unlikely to share common factors and to represent the same concept.
 *  Identification of latent factors representing  the  data.  Each  factor  coefficients (also called loadings) measures  the  correlation  between  the individual  indicator  and  the  latentfactor.  Principal  components  analysis  allows  to  extract  factors  that  account  for  the  largest amount of the variance.
 *  Rotation  of  factors  (with varimax rotation)  to  minimise  the  number  of  individual  indicators  that  have  a  high  loading  on  the  same factor. 
 *  Construction  of  the  weights for each selected indicators from  the  matrix  of  factor  loadings  after rotation, given that the square of factor loadings represents the proportion of the total unit variance of the indicator  which  is  explained  by  the  factor. 


Standard  practice  is  to  choose  factors  that:  

 * have  associated  eigenvalues  larger  than  one;  
 
 * contribute  individually  to  the  explanation  of  overall  variance  by  more  than  10%; 
 
 * contribute cumulatively to the explanation of the overall variance by more than 60%. 

## Composite Indicators calculation

The calculation of composite indicators has been performed with the [R Compind package](http://complexity.stat.unipd.it/system/files/Vidoli_Fusco.pdf).

The various method tested are:


 
### Benefit of the Doubt approach (BoD)

 ci_bod_est is the application of Data Envelopment Analysis (DEA) to the field of composite indicators. It was originally proposed by Melyn and Moesen (1991) to evaluate macroeconomic performance.
 
 BoD approach offers several advantages:
 
 *  Weights are endogenously determined by the observed performances and benchmark is not based on theoretical bounds, but it’s a linear combination of the observed best performances.
 
 *  Principle is easy to communicate:  since we are not sure about the right weights, we look for ”benefit of the doubt” weights (such that your overall relative performance index is as high as possible).
 
### Robust Benefit of the Doubt approach (RBoD) 

 ci_rbod_est is the robust version of the BoD method. It is based on the concept of the expected minimum input function of order-m so "in place of looking for the lower boundary of the support of F, as was typically the case for the full-frontier (DEA or FDH), the order-m efficiency score can be viewed as the expectation of the maximal score, when compared to m units randomly drawn from the population of units presenting a greater level of simple indicators", Daraio and Simar (2005).
 

 
### Directional Benefit of the Doubt (D-BoD)

ci_bod_dir_est model enhance non-compensatory property by introducing directional penalties in a standard BoD model in order to consider the preference structure among simple indicators.
 

### Benefit of the Doubt approach (BoD) index with constraints on weights 

ci_bod_constr_est_mpi allows for constraints (so that there is none not valued) and with a penalty as proposed by Mazziotta - Pareto (also adopted by the Italian National Institute of Statistics) 
 
### Factor analysis 

 ci_factor_est groups together collinear simple indicators to estimate a composite indicator that captures as much as possible of the information common to individual indicators.
 
### Generalized geometric mean quantity index numbers
 
ci_mean_geom_est  use the geometric mean to aggregate the single indicators. Two weighting criteria has been implemented: EQUAL: equal weighting and BOD: Benefit-of-the-Doubt weights following the Puyenbroeck and Rogge (2017) approach.

 
### Mean-Min Function (MMF) 
 
 ci_mean_min_est is an intermediate case between arithmetic mean, according to which no unbalance is penalized, and min function, according to which the penalization is maximum. It depends on two parameters that are respectively related to the intensity of penalization of unbalance (α) and intensity of complementarity (β) among indicators.
 

### Mazziotta-Pareto Index (MPI)
 
 ci_mpi_est  is a non-linear composite index method which transforms a set of individual indicators in standardized variables and summarizes them using an arithmetic mean adjusted by a "penalty" coefficient related to the variability of each unit (method of the coefficient of variation penalty).
 

### Wroclaw taxonomy method 
 
 ci_wroclaw_est  (also known as the dendric method), originally developed at the University of Wroclaw, is based on the distance from a theoretical unit characterized by the best performance for all indicators considered; the composite indicator is therefore based on the sum of euclidean distances from the ideal unit and normalized by a measure of variability of these distance (mean + 2*std).


